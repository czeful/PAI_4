

---

## Task 1 — Классификация датасета Iris

В этом проекте реализован полный цикл машинного обучения для датасета Iris с использованием трёх моделей: Decision Tree, Logistic Regression и K-Nearest Neighbors (KNN).

Что было сделано:

Загружен датасет Iris, проведён первичный анализ и проверка баланса классов. Данные разделены на train/test (80/20) с сохранением пропорций классов. Построены пайплайны моделей: Decision Tree (max_depth=3 по умолчанию), Logistic Regression с масштабированием признаков и KNN с n_neighbors=5 и масштабированием признаков. Опционально был проведён лёгкий GridSearchCV для подбора гиперпараметров. Обучение моделей сопровождалось измерением времени обучения и предсказания.

Метрики оценки качества включали Accuracy, Precision (macro), Recall (macro), F1-score (macro) и AUC (macro, ROC OvR). Для визуализации результатов построены confusion matrix для каждой модели, ROC-кривые для каждого класса, сводная таблица метрик сохранена в CSV, а также подготовлены подробные текстовые отчёты.

Результаты показали, что Decision Tree имеет высокую точность (~96%) и быстро обучается, но чувствительна к глубине. Logistic Regression достигает точности ~95%, хорошо работает с нормализованными признаками, ROC-кривые стабильные. KNN показывает точность ~94–95%, чувствителен к выбору k и масштабированию признаков. Ошибки чаще встречаются между классами versicolor и virginica, а ROC-кривые показывают хорошее разделение классов setosa.

Все графики, CSV-файлы и текстовые отчёты сохранены в папке `iris_results`.

---

## Task 2 — Детальный анализ KNN и Decision Tree на Iris

Использован стандартный датасет Iris с 4 признаками и 3 классами. Данные разделены на train/test (80/20) с сохранением пропорций. Для KNN признаки масштабированы, Decision Tree обучена и рассчитана важность признаков. Построены confusion matrix для оценки ошибок.

Исследовано влияние гиперпараметров: для KNN подбиралось оптимальное k (1–20), для Decision Tree — max_depth (1–10). Построены графики важности признаков, а также зависимость Accuracy от k и max_depth.

Результаты показали, что наиболее информативные признаки — petal length и petal width. Setosa классифицируется без ошибок, ошибки встречаются между versicolor и virginica. Оптимальное k для KNN = 6, точность ≈ 0.967; Decision Tree при max_depth = 3 достигает точности ≈ 0.967. Decision Tree устойчива и интерпретируема, KNN зависит от масштабирования и выбора k. Анализ признаков и визуализация ошибок помогают понять, какие классы распознаются лучше.

---

## Task 3 — Однослойный перцептрон на Iris 

Реализован однослойный MLP для классификации Iris (3 класса). Использован один скрытый слой с активацией (ReLU, Sigmoid, Tanh). Данные разделены на train/validation/test (60/20/20) с сохранением пропорций классов, признаки масштабированы StandardScaler. Модель обучалась с Adam, CrossEntropyLoss и early stopping.

Метрики: Loss и Accuracy на train/val, Accuracy, Precision, Recall, F1 на тестовой выборке. Также построены confusion matrix и classification report, графики кривых обучения и accuracy по активациям.

Результаты: для Iris Accuracy ≈ 0.967–0.973, для Breast Cancer ≈ 0.97–0.98. ReLU быстрее сходится, стабильнее Loss/Accuracy; Sigmoid медленнее; Tanh чуть лучше Sigmoid на ранних эпохах. Ошибки чаще между похожими классами, early stopping помогает избежать переобучения. Однослойный перцептрон хорошо справляется с малыми и линейно-разделимыми датасетами. Все результаты сохранены в папке `results_perceptron`.

---

## Task 4 — MLP на MNIST 

Загружен и нормализован датасет, train разделен на train/validation (90/10%). Построен MLP с 3 скрытыми слоями (256 → 128 → 64) + ReLU; выходной слой — 10 нейронов (Softmax через CrossEntropyLoss). Оптимизатор: Adam. Проведено обучение для комбинаций epochs = 5, 10, 20 и batch_size = 32, 64, 128, зафиксированы значения Accuracy и Loss на train и validation. Построены графики динамики обучения, визуализированы 5 корректных и 5 ошибочных предсказаний на тесте.

Результаты: наибольшая Accuracy на validation для MNIST ~98.3% (epochs=20, batch_size=64), для Fashion-MNIST ~88%. Мало эпох (5) → точность ниже (~94–95%). Большой batch_size (128) ускоряет обучение, но немного снижает точность (~0.5–1%). Лёгкое переобучение при epochs=20 и batch_size=32: train Accuracy ~99.2%, val Accuracy ~97.8%. Ошибки чаще связаны с похожими классами (MNIST: цифры «4» и «9»). С ростом эпох train_loss уменьшается, validation accuracy ≈ train accuracy, модель хорошо обобщает данные. Оптимальный размер batch ~64.

Вывод: увеличение числа эпох улучшает качество, обучение проходит стабильно, MLP корректно классифицирует данные, основные ошибки связаны с похожими классами.

